{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pitGitHub2016/PyPhD_Github/blob/master/DailyDataHandler_Base44_Betmechs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6nN4d0qrFszv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PMmPT8HOEei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61efd7a-b9d0-4bc3-9e83-070b21354c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 Fetching zip links...\n",
            "✅ Total zip links: 33\n",
            "\n",
            "💾 Downloading zips...\n",
            "🔄 Latest season for DATA identified as 2526 (2025). Will re-fetch.\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0001/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0001.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0102/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0102.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0203/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0203.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0304/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0304.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0405/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0405.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0506/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0506.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0607/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0607.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0708/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0708.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0809/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0809.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/0910/data.zip\n",
            "💾 Saved zip: football_zips/DATA_0910.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1011/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1011.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1112/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1112.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1213/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1213.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1314/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1314.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1415/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1415.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1516/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1516.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1617/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1617.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1718/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1718.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1819/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1819.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/1920/data.zip\n",
            "💾 Saved zip: football_zips/DATA_1920.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/2021/data.zip\n",
            "💾 Saved zip: football_zips/DATA_2021.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/2122/data.zip\n",
            "💾 Saved zip: football_zips/DATA_2122.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/2223/data.zip\n",
            "💾 Saved zip: football_zips/DATA_2223.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/2324/data.zip\n",
            "💾 Saved zip: football_zips/DATA_2324.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/2425/data.zip\n",
            "💾 Saved zip: football_zips/DATA_2425.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/2526/data.zip\n",
            "💾 Saved zip: football_zips/DATA_2526.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9394/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9394.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9495/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9495.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9596/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9596.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9697/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9697.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9798/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9798.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9899/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9899.zip\n",
            "⬇️  Downloading https://www.football-data.co.uk/mmz4281/9900/data.zip\n",
            "💾 Saved zip: football_zips/DATA_9900.zip\n",
            "\n",
            "🧱 Combining and normalizing...\n",
            "\n",
            "📦 Processing DATA_0001.zip\n",
            "\n",
            "📦 Processing DATA_0102.zip\n",
            "\n",
            "📦 Processing DATA_0203.zip\n",
            "\n",
            "📦 Processing DATA_0304.zip\n",
            "\n",
            "📦 Processing DATA_0405.zip\n",
            "\n",
            "📦 Processing DATA_0506.zip\n",
            "\n",
            "📦 Processing DATA_0607.zip\n",
            "\n",
            "📦 Processing DATA_0708.zip\n",
            "\n",
            "📦 Processing DATA_0809.zip\n",
            "\n",
            "📦 Processing DATA_0910.zip\n",
            "\n",
            "📦 Processing DATA_1011.zip\n",
            "\n",
            "📦 Processing DATA_1112.zip\n",
            "\n",
            "📦 Processing DATA_1213.zip\n",
            "\n",
            "📦 Processing DATA_1314.zip\n",
            "\n",
            "📦 Processing DATA_1415.zip\n",
            "\n",
            "📦 Processing DATA_1516.zip\n",
            "\n",
            "📦 Processing DATA_1617.zip\n",
            "\n",
            "📦 Processing DATA_1718.zip\n",
            "\n",
            "📦 Processing DATA_1819.zip\n",
            "\n",
            "📦 Processing DATA_1920.zip\n",
            "\n",
            "📦 Processing DATA_2021.zip\n",
            "\n",
            "📦 Processing DATA_2122.zip\n",
            "\n",
            "📦 Processing DATA_2223.zip\n",
            "\n",
            "📦 Processing DATA_2324.zip\n",
            "\n",
            "📦 Processing DATA_2425.zip\n",
            "\n",
            "📦 Processing DATA_2526.zip\n",
            "\n",
            "📦 Processing DATA_9394.zip\n",
            "\n",
            "📦 Processing DATA_9495.zip\n",
            "\n",
            "📦 Processing DATA_9596.zip\n",
            "\n",
            "📦 Processing DATA_9697.zip\n",
            "\n",
            "📦 Processing DATA_9798.zip\n",
            "\n",
            "📦 Processing DATA_9899.zip\n",
            "\n",
            "📦 Processing DATA_9900.zip\n",
            "✅ Saved combined_by_league/SC3__combined.csv (rows: 3608)\n",
            "✅ Saved combined_by_league/D1__combined.csv (rows: 6300)\n",
            "✅ Saved combined_by_league/D2__combined.csv (rows: 6284)\n",
            "✅ Saved combined_by_league/E0__combined.csv (rows: 7775)\n",
            "✅ Saved combined_by_league/E1__combined.csv (rows: 11245)\n",
            "✅ Saved combined_by_league/E2__combined.csv (rows: 11116)\n",
            "✅ Saved combined_by_league/E3__combined.csv (rows: 11195)\n",
            "✅ Saved combined_by_league/F1__combined.csv (rows: 7577)\n",
            "✅ Saved combined_by_league/F2__combined.csv (rows: 7627)\n",
            "✅ Saved combined_by_league/G1__combined.csv (rows: 4974)\n",
            "✅ Saved combined_by_league/I1__combined.csv (rows: 7771)\n",
            "✅ Saved combined_by_league/I2__combined.csv (rows: 8711)\n",
            "✅ Saved combined_by_league/N1__combined.csv (rows: 6178)\n",
            "✅ Saved combined_by_league/P1__combined.csv (rows: 5774)\n",
            "✅ Saved combined_by_league/SC0__combined.csv (rows: 4595)\n",
            "✅ Saved combined_by_league/SC1__combined.csv (rows: 3600)\n",
            "✅ Saved combined_by_league/SC2__combined.csv (rows: 3610)\n",
            "✅ Saved combined_by_league/B1__combined.csv (rows: 5479)\n",
            "✅ Saved combined_by_league/SP1__combined.csv (rows: 7772)\n",
            "✅ Saved combined_by_league/SP2__combined.csv (rows: 9521)\n",
            "✅ Saved combined_by_league/T1__combined.csv (rows: 6567)\n",
            "✅ Saved combined_by_league/EC__combined.csv (rows: 10748)\n",
            "\n",
            "🌍 Global file saved: combined_by_league/ALL_LEAGUES_combined.csv (rows: 227409)\n",
            "\n",
            "🎉 Done. Files saved in 'combined_by_league/'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "# =========================\n",
        "# 1) Fetch ZIP links\n",
        "# =========================\n",
        "def fetch_zip_links(page_url: str) -> list[str]:\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    r = session.get(page_url, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "    links = []\n",
        "    for a in soup.find_all(\"a\", href=True):\n",
        "        href = a[\"href\"].strip()\n",
        "        if \".zip\" in href.lower():\n",
        "            links.append(urljoin(page_url, href))\n",
        "    return sorted(set(links))\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 2) Download ZIPs uniquely\n",
        "\n",
        "def _season_code_to_year(code: str) -> int:\n",
        "    \"\"\"Convert season code like '9394', '2324' to start year (int).\"\"\"\n",
        "    if not code or not code.isdigit() or len(code) != 4:\n",
        "        return -1\n",
        "    try:\n",
        "        first_two = int(code[:2])\n",
        "        # Heuristic: if >= 90 → 1900s, else → 2000s\n",
        "        if first_two >= 90:\n",
        "            return 1900 + first_two\n",
        "        else:\n",
        "            return 2000 + first_two\n",
        "    except Exception:\n",
        "        return -1\n",
        "\n",
        "\n",
        "def download_zips(zip_urls, zip_dir=\"football_zips\"):\n",
        "    \"\"\"\n",
        "    Downloads zip files uniquely into zip_dir.\n",
        "    - Deletes the latest season's zip for each league before re-downloading.\n",
        "    - Renames generic \"data.zip\" into {league}_{season}.zip.\n",
        "    - Infers league code and season robustly from the URL.\n",
        "    \"\"\"\n",
        "    os.makedirs(zip_dir, exist_ok=True)\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    saved_files = []\n",
        "\n",
        "    league_groups = {}\n",
        "\n",
        "    for url in zip_urls:\n",
        "        raw_fname = os.path.basename(urlparse(url).path)\n",
        "\n",
        "        # Try to parse season + league from URL\n",
        "        parts = url.split(\"/\")\n",
        "        season_part, league_part = None, None\n",
        "\n",
        "        if len(parts) >= 3:\n",
        "            season_candidate = parts[-2]\n",
        "            if season_candidate.isdigit():\n",
        "                season_part = season_candidate\n",
        "\n",
        "        if parts and parts[-1]:\n",
        "            league_candidate = parts[-1].split(\".\")[0].upper()\n",
        "            if re.match(r\"^[A-Z0-9]{1,4}$\", league_candidate):\n",
        "                league_part = league_candidate\n",
        "\n",
        "        if not league_part:\n",
        "            league_part = \"GENERIC\"\n",
        "        if not season_part:\n",
        "            season_part = \"LATEST\"\n",
        "\n",
        "        fname = f\"{league_part}_{season_part}.zip\"\n",
        "        league_groups.setdefault(league_part, []).append((url, fname, season_part))\n",
        "\n",
        "    # --- Process each league group ---\n",
        "    for league, files in league_groups.items():\n",
        "        # Find latest season by converted year\n",
        "        season_info = [(f[2], _season_code_to_year(f[2])) for f in files if f[2].isdigit()]\n",
        "        if season_info:\n",
        "            latest_code, latest_year = max(season_info, key=lambda x: x[1])\n",
        "            latest_url, latest_fname, _ = next(f for f in files if f[2] == latest_code)\n",
        "            latest_path = os.path.join(zip_dir, latest_fname)\n",
        "\n",
        "            if os.path.exists(latest_path):\n",
        "                print(f\"🗑️ Deleting cached {league} {latest_code} ({latest_year}) → {latest_fname}\")\n",
        "                os.remove(latest_path)\n",
        "\n",
        "            print(f\"🔄 Latest season for {league} identified as {latest_code} ({latest_year}). Will re-fetch.\")\n",
        "\n",
        "        # Download files\n",
        "        for url, fname, _ in files:\n",
        "            out_path = os.path.join(zip_dir, fname)\n",
        "            if os.path.exists(out_path):\n",
        "                print(f\"✅ {fname} already exists, skipping.\")\n",
        "                saved_files.append(out_path)\n",
        "                continue\n",
        "\n",
        "            print(f\"⬇️  Downloading {url}\")\n",
        "            r = session.get(url, timeout=120)\n",
        "            r.raise_for_status()\n",
        "            with open(out_path, \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "            saved_files.append(out_path)\n",
        "            print(f\"💾 Saved zip: {out_path}\")\n",
        "\n",
        "    return saved_files\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 3) Column normalization\n",
        "# =========================\n",
        "def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cleaned = []\n",
        "    for c in df.columns:\n",
        "        cc = str(c).replace(\"\\ufeff\", \"\").strip()\n",
        "        cleaned.append(cc)\n",
        "    df.columns = cleaned\n",
        "\n",
        "    lower_map = {c.lower(): c for c in df.columns}\n",
        "    if \"div\" in lower_map:\n",
        "        df.rename(columns={lower_map[\"div\"]: \"Div\"}, inplace=True)\n",
        "    lower_map = {c.lower(): c for c in df.columns}\n",
        "    if \"date\" in lower_map and lower_map[\"date\"] != \"Date\":\n",
        "        df.rename(columns={lower_map[\"date\"]: \"Date\"}, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 4) Robust CSV reader\n",
        "# =========================\n",
        "def _read_csv_from_zip(zf: zipfile.ZipFile, member: str) -> pd.DataFrame:\n",
        "    data = zf.read(member)\n",
        "    for enc in [\"utf-8\", \"latin-1\"]:\n",
        "        for sep in [None, \",\", \";\"]:\n",
        "            try:\n",
        "                df = pd.read_csv(io.BytesIO(data), encoding=enc, sep=sep, engine=\"python\", on_bad_lines=\"skip\")\n",
        "                if not df.empty:\n",
        "                    return _normalize_columns(df)\n",
        "            except Exception:\n",
        "                continue\n",
        "    return pd.DataFrame()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 5) Date normalization\n",
        "# =========================\n",
        "def normalize_date_column(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if \"Date\" not in df.columns:\n",
        "        return df\n",
        "\n",
        "    if \"DateRaw\" not in df.columns:\n",
        "        df.rename(columns={\"Date\": \"DateRaw\"}, inplace=True)\n",
        "    else:\n",
        "        df[\"DateRaw\"] = df[\"Date\"].astype(str)\n",
        "\n",
        "    date_raw_series = df[\"DateRaw\"].astype(str).str.strip()\n",
        "    out_year, out_month, out_day = [], [], []\n",
        "    norm_date_strings = []\n",
        "\n",
        "    for raw in date_raw_series:\n",
        "        raw = raw.strip()\n",
        "        day = month = year = None\n",
        "        parts = raw.split(\"/\") if \"/\" in raw else (raw.split(\"-\") if \"-\" in raw else [])\n",
        "\n",
        "        if len(parts) == 3:\n",
        "            a, b, c = [p.strip() for p in parts]\n",
        "            if len(a) == 4 and a.isdigit():\n",
        "                year, month, day = a, b, c\n",
        "            else:\n",
        "                day, month, year = a, b, c\n",
        "\n",
        "            def to_int(x):\n",
        "                try:\n",
        "                    return int(x)\n",
        "                except Exception:\n",
        "                    return None\n",
        "\n",
        "            di, mi, yi = to_int(day), to_int(month), to_int(year)\n",
        "            if yi is not None and len(year) == 2:\n",
        "                yi = 1900 + yi if yi > 30 else 2000 + yi\n",
        "\n",
        "            def in_range(x, lo, hi):\n",
        "                return x is not None and lo <= x <= hi\n",
        "\n",
        "            if not in_range(mi, 1, 12) and in_range(di, 1, 12):\n",
        "                di, mi = mi, di\n",
        "\n",
        "            if in_range(di, 1, 31) and in_range(mi, 1, 12) and yi is not None:\n",
        "                dd, mm, yyyy = f\"{di:02d}\", f\"{mi:02d}\", f\"{yi:04d}\"\n",
        "                out_day.append(dd); out_month.append(mm); out_year.append(yyyy)\n",
        "                norm_date_strings.append(f\"{yyyy}-{mm}-{dd}\")\n",
        "            else:\n",
        "                out_day.append(None); out_month.append(None); out_year.append(None); norm_date_strings.append(None)\n",
        "        else:\n",
        "            out_day.append(None); out_month.append(None); out_year.append(None); norm_date_strings.append(None)\n",
        "\n",
        "    df[\"DateDay\"], df[\"DateMonth\"], df[\"DateYear\"] = out_day, out_month, out_year\n",
        "    df[\"Date\"] = pd.to_datetime(norm_date_strings, errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 6) Filtering rules\n",
        "# =========================\n",
        "def _find_existing_cols_case_insensitive(df: pd.DataFrame, wanted: list[str]) -> list[str]:\n",
        "    wanted_lower = {w.lower(): w for w in wanted}\n",
        "    actual = []\n",
        "    for c in df.columns:\n",
        "        if c.lower() in wanted_lower:\n",
        "            actual.append(c)\n",
        "    return actual\n",
        "\n",
        "def filter_by_results_and_odds(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    results_wanted = [\"FTHG\", \"FTAG\", \"FTR\"]\n",
        "    result_cols_present = _find_existing_cols_case_insensitive(df, results_wanted)\n",
        "    if result_cols_present:\n",
        "        df = df.dropna(subset=result_cols_present, how=\"any\")\n",
        "\n",
        "    odds_prefixes = [\n",
        "        \"1XB\", \"B365\", \"BF\", \"BFD\", \"BFA\", \"BFDH\", \"BFDD\", \"BFDA\",\n",
        "        \"BMGM\", \"BV\", \"BS\", \"BWH\",\n",
        "        \"CL\", \"GB\", \"IW\", \"LB\", \"PS\", \"SO\", \"SB\", \"SJ\", \"SY\", \"VC\", \"WH\",\n",
        "        \"Bb\", \"Max\", \"Avg\", \"BFE\"\n",
        "    ]\n",
        "    odds_cols = [c for c in df.columns if any(c.upper().startswith(p) for p in odds_prefixes)]\n",
        "    if odds_cols:\n",
        "        df = df[~df[odds_cols].isna().all(axis=1)]\n",
        "    return df\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 7) Combine per-league + global\n",
        "# =========================\n",
        "def combine_all_leagues(zip_dir=\"football_zips\", out_dir=\"combined_by_league\", global_file=\"ALL_LEAGUES_combined.csv\"):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    zip_files = [os.path.join(zip_dir, f) for f in os.listdir(zip_dir) if f.lower().endswith(\".zip\")]\n",
        "\n",
        "    league_data, all_data = {}, []\n",
        "\n",
        "    for zp in sorted(zip_files):\n",
        "        print(f\"\\n📦 Processing {os.path.basename(zp)}\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(zp, \"r\") as zf:\n",
        "                members = [m for m in zf.namelist() if m.lower().endswith(\".csv\")]\n",
        "                if not members:\n",
        "                    print(\"  ⚠️ No CSVs inside zip.\"); continue\n",
        "\n",
        "                for m in members:\n",
        "                    df = _read_csv_from_zip(zf, m)\n",
        "                    if df.empty:\n",
        "                        print(f\"  ⚠️ {m} yielded 0 rows.\"); continue\n",
        "\n",
        "                    if \"Div\" not in df.columns:\n",
        "                        df[\"Div\"] = pd.NA\n",
        "                    df[\"Div\"] = df[\"Div\"].ffill().bfill()\n",
        "\n",
        "                    df = normalize_date_column(df)\n",
        "                    df = filter_by_results_and_odds(df)\n",
        "\n",
        "                    for league_code, grp in df.groupby(\"Div\", dropna=True):\n",
        "                        league_code = str(league_code).strip().upper()\n",
        "                        if not league_code or league_code == \"NAN\":\n",
        "                            continue\n",
        "                        league_data.setdefault(league_code, []).append(grp)\n",
        "                        all_data.append(grp)\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"  ❌ Bad zip: {zp}, skipping.\"); continue\n",
        "\n",
        "    for league_code, dfs in league_data.items():\n",
        "        combined_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
        "        combined_df[\"Div\"] = combined_df[\"Div\"].ffill().bfill().fillna(league_code)\n",
        "        if \"Date\" in combined_df.columns:\n",
        "            combined_df = combined_df.sort_values(by=\"Date\", ascending=True, na_position=\"last\")\n",
        "\n",
        "        out_path = os.path.join(out_dir, f\"{league_code}__combined.csv\")\n",
        "        short_out_path = os.path.join(out_dir, f\"{league_code}_short_combined.csv\")\n",
        "\n",
        "        combined_df = combined_df[combined_df['DateYear'].astype(float) >= 2005]\n",
        "        combined_df = combined_df[[x for x in combined_df.columns if \"Unnamed:\" not in x]]\n",
        "\n",
        "        combined_df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
        "        combined_df.tail(50).to_csv(short_out_path, index=False, encoding=\"utf-8\")\n",
        "        print(f\"✅ Saved {out_path} (rows: {len(combined_df)})\")\n",
        "\n",
        "    if all_data:\n",
        "        global_df = pd.concat(all_data, ignore_index=True, sort=False)\n",
        "        if \"Date\" in global_df.columns:\n",
        "            global_df = global_df.sort_values(by=[\"Date\", \"Div\"], ascending=[True, True], na_position=\"last\")\n",
        "        global_path = os.path.join(out_dir, global_file)\n",
        "        global_df.to_csv(global_path, index=False, encoding=\"utf-8\")\n",
        "        print(f\"\\n🌍 Global file saved: {global_path} (rows: {len(global_df)})\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 8) Master run\n",
        "# =========================\n",
        "def build_all_leagues():\n",
        "    print(\"🔎 Fetching zip links...\")\n",
        "    main_links = fetch_zip_links(\"https://www.football-data.co.uk/downloadm.php\")\n",
        "    new_links  = fetch_zip_links(\"https://www.football-data.co.uk/all_new_data.php\")\n",
        "    zip_urls = sorted(set(main_links + new_links))\n",
        "    print(f\"✅ Total zip links: {len(zip_urls)}\")\n",
        "\n",
        "    print(\"\\n💾 Downloading zips...\")\n",
        "    download_zips(zip_urls, zip_dir=\"football_zips\")\n",
        "\n",
        "    print(\"\\n🧱 Combining and normalizing...\")\n",
        "    combine_all_leagues(zip_dir=\"football_zips\", out_dir=\"combined_by_league\")\n",
        "\n",
        "    print(\"\\n🎉 Done. Files saved in 'combined_by_league/'\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_all_leagues()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud-hy4-VCgvX",
        "outputId": "58621b50-38db-407c-ff18-efb5f1effbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  E0: Premier League\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'E0', 'limit': 100}\n",
            "✅ Success: Successfully fetched 100 records from History_E0.\n",
            "📊 Successfully fetched 100 records\n",
            "  D1: Bundesliga\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'D1', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_D1.\n",
            "No data returned or an error occurred.\n",
            "  SP1: La Liga\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'SP1', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_SP1.\n",
            "No data returned or an error occurred.\n",
            "  I1: Serie A\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'I1', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_I1.\n",
            "No data returned or an error occurred.\n",
            "  F1: Ligue 1\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'F1', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_F1.\n",
            "No data returned or an error occurred.\n",
            "  E1: Championship\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'E1', 'limit': 100}\n",
            "✅ Success: Successfully fetched 100 records from History_E1.\n",
            "📊 Successfully fetched 100 records\n",
            "  E2: League 1\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'E2', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_E2.\n",
            "No data returned or an error occurred.\n",
            "  E3: League 2\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'E3', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_E3.\n",
            "No data returned or an error occurred.\n",
            "  EC: Conference\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'EC', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_EC.\n",
            "No data returned or an error occurred.\n",
            "  SC0: Scottish Premiership\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'SC0', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_SC0.\n",
            "No data returned or an error occurred.\n",
            "  D2: Bundesliga 2\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'D2', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_D2.\n",
            "No data returned or an error occurred.\n",
            "  I2: Serie B\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'I2', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_I2.\n",
            "No data returned or an error occurred.\n",
            "  SP2: Segunda Division\n",
            "📞 Calling 'fetchRecentHistory' with payload: {'leagueCode': 'SP2', 'limit': 100}\n",
            "✅ Success: Successfully fetched 0 records from History_SP2.\n",
            "No data returned or an error occurred.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "# --- ⚙️ CONFIGURATION ---\n",
        "APP_HOSTNAME = \"betmechs-ee8f45ee.base44.app\"\n",
        "BASE44_API_KEY = \"09b8177c650048309207ea18b26b58fb\"\n",
        "\n",
        "# Available leagues for data fetching\n",
        "AVAILABLE_LEAGUES = {\n",
        "    \"E0\": \"Premier League\", \"D1\": \"Bundesliga\", \"SP1\": \"La Liga\", \"I1\": \"Serie A\", \"F1\": \"Ligue 1\",\n",
        "    \"E1\": \"Championship\", \"E2\": \"League 1\", \"E3\": \"League 2\", \"EC\": \"Conference\",\n",
        "    \"SC0\": \"Scottish Premiership\", \"D2\": \"Bundesliga 2\", \"I2\": \"Serie B\", \"SP2\": \"Segunda Division\",\n",
        "    # Add more as needed\n",
        "}\n",
        "\n",
        "def call_backend_function(function_name, payload={}, timeout=60):\n",
        "    \"\"\"Helper to call backend functions.\"\"\"\n",
        "    url = f\"https://{APP_HOSTNAME}/api/functions/{function_name}\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {BASE44_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    print(f\"📞 Calling '{function_name}' with payload: {payload}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        response_data = response.json()\n",
        "        print(f\"✅ Success: {response_data.get('message', 'OK')}\")\n",
        "        return True, response_data.get('data', [])\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ ERROR in '{function_name}': {e}\", file=sys.stderr)\n",
        "        if hasattr(e, 'response') and e.response:\n",
        "            try:\n",
        "                error_details = e.response.json()\n",
        "                print(f\"   Response: {error_details}\", file=sys.stderr)\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"   Response (non-JSON): {e.response.text}\", file=sys.stderr)\n",
        "        return False, []\n",
        "\n",
        "def fetch_recent_league_data(league_code, limit=100):\n",
        "    \"\"\"Fetch the most recent N records from a specific league's history table.\"\"\"\n",
        "    if league_code not in AVAILABLE_LEAGUES:\n",
        "        print(f\"❌ Invalid league code: {league_code}\")\n",
        "        return\n",
        "\n",
        "    out_dir=\"latest_history_in_base44_backend\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    success, data = call_backend_function(\"fetchRecentHistory\", {\"leagueCode\": league_code, \"limit\": limit})\n",
        "\n",
        "    if success and data:\n",
        "        print(f\"📊 Successfully fetched {len(data)} records\")\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        outPath = os.path.join(out_dir, f\"{league_code}__latest.csv\")\n",
        "        df.to_csv(outPath, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    else:\n",
        "        print(\"No data returned or an error occurred.\")\n",
        "\n",
        "def interactive_fetch_menu():\n",
        "\n",
        "    for code, name in AVAILABLE_LEAGUES.items():\n",
        "        print(f\"  {code}: {name}\")\n",
        "        try:\n",
        "            fetch_recent_league_data(code, 100)\n",
        "        except Exception as e:\n",
        "            print(\"❌ Error ... \", e)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interactive_fetch_menu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define the root directories as used in your original notebook\n",
        "LATEST_DATA_DIR = 'latest_history_in_base44_backend'\n",
        "SOURCE_DATA_DIR = 'combined_by_league'\n",
        "\n",
        "def find_new_records_chronological(league_code: str, lookback_days: int = 14) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compares the latest combined CSV from football-data.co.uk with the last\n",
        "    N records from the Base44 backend by using a chronological filter.\n",
        "    This is an efficient approach for daily syncs.\n",
        "\n",
        "    Args:\n",
        "        league_code (str): The league code (e.g., 'E0' for Premier League).\n",
        "        lookback_days (int): The number of days to look back from the most\n",
        "                             recent date in the backend data for comparison.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing only the new records, or an empty\n",
        "                      DataFrame if no new records are found.\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Searching for new records for league: {league_code} using chronological filtering.\")\n",
        "\n",
        "    # Step 1: Define file paths for the two datasets\n",
        "    latest_backend_path = os.path.join(LATEST_DATA_DIR, f'{league_code}__latest.csv')\n",
        "    combined_source_path = os.path.join(SOURCE_DATA_DIR, f'{league_code}__combined.csv')\n",
        "\n",
        "    # Step 2: Check if both files exist before proceeding\n",
        "    if not os.path.exists(latest_backend_path):\n",
        "        print(f\"❌ Error: Backend data file not found at '{latest_backend_path}'.\")\n",
        "        return pd.DataFrame()\n",
        "    if not os.path.exists(combined_source_path):\n",
        "        print(f\"❌ Error: Source data file not found at '{combined_source_path}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Step 3: Load the datasets into pandas DataFrames\n",
        "    try:\n",
        "        df_source = pd.read_csv(combined_source_path, encoding='utf-8')\n",
        "        df_backend = pd.read_csv(latest_backend_path, encoding='utf-8')\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading CSV files: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"✅ Loaded source file with {len(df_source)} records.\")\n",
        "    print(f\"✅ Loaded backend file with {len(df_backend)} records.\")\n",
        "\n",
        "    # Step 4: Ensure consistent data types and create a unique key for comparison\n",
        "    # We now use the Date, Teams, and Bet365 odds as a robust key\n",
        "    key_columns = ['Date', 'HomeTeam', 'AwayTeam', 'B365H', 'B365D', 'B365A']\n",
        "\n",
        "    # Handle missing odds columns gracefully\n",
        "    for col in ['B365H', 'B365D', 'B365A']:\n",
        "        if col not in df_source.columns:\n",
        "            df_source[col] = ''\n",
        "        if col not in df_backend.columns:\n",
        "            df_backend[col] = ''\n",
        "\n",
        "    # Convert 'Date' to a datetime object for filtering\n",
        "    df_source['Date'] = pd.to_datetime(df_source['Date'], errors='coerce')\n",
        "    df_backend['Date'] = pd.to_datetime(df_backend['Date'], errors='coerce')\n",
        "\n",
        "    # Drop rows with invalid dates\n",
        "    df_source.dropna(subset=['Date'], inplace=True)\n",
        "    df_backend.dropna(subset=['Date'], inplace=True)\n",
        "\n",
        "    # Step 5: Chronological Filtering\n",
        "    # Find the latest date in the backend data to set the filter start point\n",
        "    if df_backend.empty:\n",
        "      print(\"Backend data is empty. Cannot perform chronological filter.\")\n",
        "      return pd.DataFrame()\n",
        "\n",
        "    latest_source_date = df_source['Date'].max()\n",
        "    latest_backend_date = df_backend['Date'].max()\n",
        "    #filter_start_date = latest_source_date\n",
        "    filter_start_date = latest_backend_date\n",
        "    #filter_start_date = latest_backend_date - timedelta(days=lookback_days)\n",
        "    print(\"latest_source_date = \", latest_source_date)\n",
        "    print(\"latest_backend_date = \", latest_backend_date)\n",
        "    print(\"filter_start_date = \", filter_start_date)\n",
        "\n",
        "    df_source_filtered = df_source[df_source['Date'] >= latest_backend_date].copy()\n",
        "    df_backend_filtered = df_backend[df_backend['Date'] >= latest_backend_date].copy()\n",
        "    print(\"df_source_filtered\")\n",
        "    print(df_source_filtered)\n",
        "    print(\"df_backend_filtered\")\n",
        "    print(df_backend_filtered)\n",
        "\n",
        "    print(f\"⏱️ Filtering both datasets from {latest_backend_date.strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "    # Step 6: Create the unique key for comparison\n",
        "    df_source_filtered['unique_key'] = df_source_filtered[key_columns].astype(str).agg('-'.join, axis=1)\n",
        "    df_backend_filtered['unique_key'] = df_backend_filtered[key_columns].astype(str).agg('-'.join, axis=1)\n",
        "\n",
        "    # Step 7: Identify new records using a left anti-join\n",
        "    merged = df_source_filtered.merge(df_backend_filtered, on='unique_key', how='left', indicator=True)\n",
        "    new_records_df = merged[merged['_merge'] == 'left_only'].copy()\n",
        "\n",
        "    # Drop the temporary merge indicator and unique key columns\n",
        "    new_records_df.drop(columns=['_merge', 'unique_key'], inplace=True)\n",
        "\n",
        "    if not new_records_df.empty:\n",
        "        print(f\"✅ Found {len(new_records_df)} new records to upload.\")\n",
        "    else:\n",
        "        print(\"🎉 No new records found. Your backend data is up to date!\")\n",
        "\n",
        "    new_records_df = new_records_df[[x for x in new_records_df.columns if \"_x\" in x]]\n",
        "    new_records_df.columns = [x.split(\"_\")[0] for x in new_records_df.columns]\n",
        "    print(new_records_df.columns)\n",
        "    new_records_df = new_records_df[df_source.columns]\n",
        "\n",
        "    return new_records_df\n",
        "\n",
        "# --- Demonstration of Usage ---\n",
        "if __name__ == '__main__':\n",
        "    league_code = \"E1\"\n",
        "    new_data_to_upload = find_new_records_chronological(league_code)\n",
        "\n",
        "    if not new_data_to_upload.empty:\n",
        "        print(\"\\nReady to upload the following new records:\")\n",
        "        print(new_data_to_upload)\n",
        "\n",
        "        os.makedirs(\"new_data_to_upload\", exist_ok=True)\n",
        "        new_data_to_upload.to_csv(\"new_data_to_upload/\"+league_code+\"_latestRun.csv\",index=False)\n",
        "        print(\"Succesfully stored new data ... ready to upload !!!\")\n",
        "    else:\n",
        "      new_data_to_upload.to_csv(\"new_data_to_upload/\"+league_code+\"_latestRun.csv\",index=False)\n",
        "      print(\"new_data_to_upload.empty!!!!\")"
      ],
      "metadata": {
        "id": "9w3bXYGm-NrM",
        "outputId": "91c2ab01-e399-4457-82ed-98b35fb6b409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Searching for new records for league: E1 using chronological filtering.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3281635508.py:40: DtypeWarning: Columns (107) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_source = pd.read_csv(combined_source_path, encoding='utf-8')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded source file with 11245 records.\n",
            "✅ Loaded backend file with 100 records.\n",
            "latest_source_date =  2025-09-14 00:00:00\n",
            "latest_backend_date =  2024-04-01 00:00:00\n",
            "filter_start_date =  2024-04-01 00:00:00\n",
            "df_source_filtered\n",
            "      Div     DateRaw       HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
            "10546  E1  01/04/2024        Ipswich     Southampton   3.0   2.0   H   1.0   \n",
            "10547  E1  01/04/2024        Swansea             QPR   0.0   1.0   A   0.0   \n",
            "10548  E1  01/04/2024     Sunderland       Blackburn   1.0   5.0   A   0.0   \n",
            "10549  E1  01/04/2024          Stoke    Huddersfield   1.0   1.0   D   0.0   \n",
            "10550  E1  01/04/2024  Middlesbrough  Sheffield Weds   2.0   0.0   H   1.0   \n",
            "...    ..         ...            ...             ...   ...   ...  ..   ...   \n",
            "11240  E1  13/09/2025      West Brom           Derby   0.0   1.0   A   0.0   \n",
            "11241  E1  13/09/2025        Watford       Blackburn   0.0   1.0   A   0.0   \n",
            "11242  E1  13/09/2025        Preston   Middlesbrough   2.0   2.0   D   1.0   \n",
            "11243  E1  13/09/2025        Swansea            Hull   2.0   2.0   D   1.0   \n",
            "11244  E1  14/09/2025    Southampton      Portsmouth   0.0   0.0   D   0.0   \n",
            "\n",
            "       HTAG HTR  ...  BMGMCA  BVCH  BVCD  BVCA  CLCH  CLCD  CLCA  LBCH  LBCD  \\\n",
            "10546   2.0   A  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "10547   0.0   D  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "10548   2.0   A  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "10549   1.0   A  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "10550   0.0   H  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "...     ...  ..  ...     ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
            "11240   0.0   D  ...    5.00  1.75   3.5  5.00  1.80  3.40  4.80  1.80  3.40   \n",
            "11241   0.0   D  ...    3.10  2.50   3.2  2.90  2.37  3.25  3.00  2.37  3.25   \n",
            "11242   0.0   H  ...    2.33  3.10   3.3  2.30  3.10  3.30  2.30  3.10  3.30   \n",
            "11243   1.0   D  ...    4.70  1.80   3.7  4.33  1.80  3.60  4.33  1.80  3.60   \n",
            "11244   0.0   D  ...    4.50  1.70   3.9  4.60  1.80  3.90  4.20  1.75  3.80   \n",
            "\n",
            "       LBCA  \n",
            "10546   NaN  \n",
            "10547   NaN  \n",
            "10548   NaN  \n",
            "10549   NaN  \n",
            "10550   NaN  \n",
            "...     ...  \n",
            "11240  4.80  \n",
            "11241  3.00  \n",
            "11242  2.30  \n",
            "11243  4.33  \n",
            "11244  4.20  \n",
            "\n",
            "[699 rows x 218 columns]\n",
            "df_backend_filtered\n",
            "  Div     DateRaw    HomeTeam      AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
            "0  E1  2024-04-01     Ipswich   Southampton     3     2   H     1     2   A   \n",
            "1  E1  2024-04-01     Swansea           QPR     0     1   A     0     0   D   \n",
            "2  E1  2024-04-01       Stoke  Huddersfield     1     1   D     0     1   A   \n",
            "3  E1  2024-04-01  Sunderland     Blackburn     1     5   A     0     2   A   \n",
            "\n",
            "   ...  CLCA LBCH  LBCD  LBCA                        id  \\\n",
            "0  ...   NaN  NaN   NaN   NaN  68c9c159e4a90d3d9d7faaa3   \n",
            "1  ...   NaN  NaN   NaN   NaN  68c9c159e4a90d3d9d7faaa4   \n",
            "2  ...   NaN  NaN   NaN   NaN  68c9c159e4a90d3d9d7faaa6   \n",
            "3  ...   NaN  NaN   NaN   NaN  68c9c159e4a90d3d9d7faaa5   \n",
            "\n",
            "                 created_date                updated_date  \\\n",
            "0  2025-09-16T19:58:17.459000  2025-09-16T19:58:17.459000   \n",
            "1  2025-09-16T19:58:17.459000  2025-09-16T19:58:17.459000   \n",
            "2  2025-09-16T19:58:17.459000  2025-09-16T19:58:17.459000   \n",
            "3  2025-09-16T19:58:17.459000  2025-09-16T19:58:17.459000   \n",
            "\n",
            "                                  created_by_id  \\\n",
            "0  service_7425d2b2-bd68-449d-ae56-44e501574fa0   \n",
            "1  service_7425d2b2-bd68-449d-ae56-44e501574fa0   \n",
            "2  service_7425d2b2-bd68-449d-ae56-44e501574fa0   \n",
            "3  service_7425d2b2-bd68-449d-ae56-44e501574fa0   \n",
            "\n",
            "                                          created_by  is_sample  \n",
            "0  service+7425d2b2-bd68-449d-ae56-44e501574fa0@n...      False  \n",
            "1  service+7425d2b2-bd68-449d-ae56-44e501574fa0@n...      False  \n",
            "2  service+7425d2b2-bd68-449d-ae56-44e501574fa0@n...      False  \n",
            "3  service+7425d2b2-bd68-449d-ae56-44e501574fa0@n...      False  \n",
            "\n",
            "[4 rows x 224 columns]\n",
            "⏱️ Filtering both datasets from 2024-04-01.\n",
            "✅ Found 695 new records to upload.\n",
            "Index(['Div', 'DateRaw', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG',\n",
            "       'HTAG', 'HTR',\n",
            "       ...\n",
            "       'BMGMCA', 'BVCH', 'BVCD', 'BVCA', 'CLCH', 'CLCD', 'CLCA', 'LBCH',\n",
            "       'LBCD', 'LBCA'],\n",
            "      dtype='object', length=218)\n",
            "\n",
            "Ready to upload the following new records:\n",
            "    Div     DateRaw       HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
            "4    E1  01/04/2024  Middlesbrough  Sheffield Weds   2.0   0.0   H   1.0   \n",
            "5    E1  01/04/2024       Plymouth    Bristol City   0.0   1.0   A   0.0   \n",
            "6    E1  01/04/2024       Coventry         Cardiff   1.0   2.0   A   1.0   \n",
            "7    E1  01/04/2024     Birmingham         Preston   1.0   0.0   H   0.0   \n",
            "8    E1  01/04/2024      Leicester         Norwich   3.0   1.0   H   1.0   \n",
            "..   ..         ...            ...             ...   ...   ...  ..   ...   \n",
            "694  E1  13/09/2025      West Brom           Derby   0.0   1.0   A   0.0   \n",
            "695  E1  13/09/2025        Watford       Blackburn   0.0   1.0   A   0.0   \n",
            "696  E1  13/09/2025        Preston   Middlesbrough   2.0   2.0   D   1.0   \n",
            "697  E1  13/09/2025        Swansea            Hull   2.0   2.0   D   1.0   \n",
            "698  E1  14/09/2025    Southampton      Portsmouth   0.0   0.0   D   0.0   \n",
            "\n",
            "     HTAG HTR  ...  BMGMCA  BVCH  BVCD  BVCA  CLCH  CLCD  CLCA  LBCH  LBCD  \\\n",
            "4     0.0   H  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "5     0.0   D  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "6     1.0   D  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "7     0.0   D  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "8     1.0   D  ...     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
            "..    ...  ..  ...     ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
            "694   0.0   D  ...    5.00  1.75   3.5  5.00  1.80  3.40  4.80  1.80  3.40   \n",
            "695   0.0   D  ...    3.10  2.50   3.2  2.90  2.37  3.25  3.00  2.37  3.25   \n",
            "696   0.0   H  ...    2.33  3.10   3.3  2.30  3.10  3.30  2.30  3.10  3.30   \n",
            "697   1.0   D  ...    4.70  1.80   3.7  4.33  1.80  3.60  4.33  1.80  3.60   \n",
            "698   0.0   D  ...    4.50  1.70   3.9  4.60  1.80  3.90  4.20  1.75  3.80   \n",
            "\n",
            "     LBCA  \n",
            "4     NaN  \n",
            "5     NaN  \n",
            "6     NaN  \n",
            "7     NaN  \n",
            "8     NaN  \n",
            "..    ...  \n",
            "694  4.80  \n",
            "695  3.00  \n",
            "696  2.30  \n",
            "697  4.33  \n",
            "698  4.20  \n",
            "\n",
            "[695 rows x 218 columns]\n",
            "Succesfully stored new data ... ready to upload !!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# --- ⚙️ CONFIGURATION ---\n",
        "APP_HOSTNAME = \"betmechs-ee8f45ee.base44.app\"\n",
        "BASE44_API_KEY = \"09b8177c650048309207ea18b26b58fb\"\n",
        "REQUEST_DELAY = 1.0  # 1 second delay between requests\n",
        "\n",
        "# Available leagues for data upload\n",
        "AVAILABLE_LEAGUES = {\n",
        "    # England\n",
        "    \"E0\": \"Premier League\", \"E1\": \"Championship\", \"E2\": \"League 1\", \"E3\": \"League 2\", \"EC\": \"Conference\",\n",
        "    # Scotland\n",
        "    \"SC0\": \"Scottish Premiership\", \"SC1\": \"Scottish Championship\", \"SC2\": \"Scottish League 1\", \"SC3\": \"Scottish League 2\",\n",
        "    # Germany\n",
        "    \"D1\": \"Bundesliga\", \"D2\": \"Bundesliga 2\",\n",
        "    # Italy\n",
        "    \"I1\": \"Serie A\", \"I2\": \"Serie B\",\n",
        "    # Spain\n",
        "    \"SP1\": \"La Liga\", \"SP2\": \"Segunda Division\",\n",
        "    # France\n",
        "    \"F1\": \"Ligue 1\", \"F2\": \"Ligue 2\",\n",
        "    # Other leagues\n",
        "    \"N1\": \"Eredivisie\", \"B1\": \"Belgian Pro League\", \"P1\": \"Primeira Liga\", \"P2\": \"Liga de Honra\",\n",
        "    \"T1\": \"Super Lig\", \"G1\": \"Super League Greece\"\n",
        "}\n",
        "\n",
        "def call_backend_function(function_name, payload={}, timeout=300):\n",
        "    \"\"\"Helper to call backend functions with extended timeout for upload operations.\"\"\"\n",
        "    url = f\"https://{APP_HOSTNAME}/api/functions/{function_name}\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {BASE44_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    print(f\"📞 Calling '{function_name}' for league {payload.get('leagueCode', 'unknown')}...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        response_data = response.json()\n",
        "        print(f\"✅ Success: {response_data.get('message', 'OK')}\")\n",
        "\n",
        "        # Print detailed log if available\n",
        "        if 'log' in response_data:\n",
        "            for log_entry in response_data['log']:\n",
        "                print(f\"   📋 {log_entry}\")\n",
        "\n",
        "        # Add delay after each request to avoid rate limits\n",
        "        time.sleep(REQUEST_DELAY)\n",
        "        return True, response_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ ERROR in '{function_name}': {e}\", file=sys.stderr)\n",
        "        if hasattr(e, 'response') and e.response:\n",
        "            try:\n",
        "                error_details = e.response.json()\n",
        "                print(f\"   Response: {error_details}\", file=sys.stderr)\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"   Response (non-JSON): {e.response.text}\", file=sys.stderr)\n",
        "        time.sleep(REQUEST_DELAY)\n",
        "        return False, None\n",
        "\n",
        "def generate_sample_data(league_code, num_matches=10):\n",
        "    \"\"\"Generate sample match data for testing.\"\"\"\n",
        "    sample_matches = []\n",
        "    teams = {\n",
        "        \"E0\": [\"Arsenal\", \"Chelsea\", \"Liverpool\", \"Man City\", \"Man United\", \"Tottenham\"],\n",
        "        \"D1\": [\"Bayern Munich\", \"Dortmund\", \"RB Leipzig\", \"Bayer Leverkusen\"],\n",
        "        \"SP1\": [\"Real Madrid\", \"Barcelona\", \"Atletico Madrid\", \"Sevilla\"],\n",
        "        \"I1\": [\"Juventus\", \"AC Milan\", \"Inter\", \"Napoli\"],\n",
        "        \"F1\": [\"PSG\", \"Lyon\", \"Marseille\", \"Monaco\"]\n",
        "    }\n",
        "\n",
        "    league_teams = teams.get(league_code, [\"Team A\", \"Team B\", \"Team C\", \"Team D\"])\n",
        "\n",
        "    for i in range(num_matches):\n",
        "        home_team = league_teams[i % len(league_teams)]\n",
        "        away_team = league_teams[(i + 1) % len(league_teams)]\n",
        "\n",
        "        if home_team == away_team:\n",
        "            away_team = league_teams[(i + 2) % len(league_teams)]\n",
        "\n",
        "        match = {\n",
        "            \"Div\": league_code,\n",
        "            \"Date\": f\"15/08/24\",  # Use consistent date format\n",
        "            \"HomeTeam\": home_team,\n",
        "            \"AwayTeam\": away_team,\n",
        "            \"FTHG\": i % 4,  # Home goals 0-3\n",
        "            \"FTAG\": (i + 1) % 3,  # Away goals 0-2\n",
        "            \"FTR\": \"H\" if (i % 4) > ((i + 1) % 3) else (\"A\" if (i % 4) < ((i + 1) % 3) else \"D\"),\n",
        "            \"B365H\": round(1.5 + (i % 10) * 0.3, 2),  # Sample odds\n",
        "            \"B365D\": round(3.0 + (i % 5) * 0.2, 2),\n",
        "            \"B365A\": round(2.0 + (i % 8) * 0.4, 2),\n",
        "            \"Referee\": f\"Referee {i + 1}\"\n",
        "        }\n",
        "        sample_matches.append(match)\n",
        "\n",
        "    return sample_matches\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    \"\"\"Read match data from a CSV file.\"\"\"\n",
        "    matches = []\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            for row in reader:\n",
        "                # Convert empty strings to None\n",
        "                processed_row = {}\n",
        "                for key, value in row.items():\n",
        "                    processed_row[key] = value if value.strip() else None\n",
        "                matches.append(processed_row)\n",
        "\n",
        "        print(f\"📁 Successfully read {len(matches)} matches from {file_path}\")\n",
        "        return matches\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ File not found: {file_path}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading CSV file: {e}\")\n",
        "        return []\n",
        "\n",
        "def upload_data_to_league(league_code, match_data):\n",
        "    \"\"\"Upload match data to a specific league table. This function only appends data.\"\"\"\n",
        "    if league_code not in AVAILABLE_LEAGUES:\n",
        "        print(f\"❌ Invalid league code: {league_code}\")\n",
        "        print(f\"Available leagues: {', '.join(AVAILABLE_LEAGUES.keys())}\")\n",
        "        return False\n",
        "\n",
        "    if not match_data:\n",
        "        print(f\"❌ No match data provided for {league_code}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"🚀 Starting upload for {AVAILABLE_LEAGUES[league_code]} ({league_code})\")\n",
        "    print(f\"📊 Appending {len(match_data)} matches...\")\n",
        "\n",
        "    payload = {\n",
        "        \"leagueCode\": league_code,\n",
        "        \"matchData\": match_data,\n",
        "    }\n",
        "\n",
        "    success, result = call_backend_function(\"uploadHistoricalData\", payload)\n",
        "\n",
        "    if success and result:\n",
        "        inserted_count = result.get('recordsInserted', 0)\n",
        "        print(f\"✅ Successfully appended {inserted_count} matches to {league_code}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"❌ Failed to upload data to {league_code}\")\n",
        "        return False\n",
        "\n",
        "def bulk_upload_sample_data():\n",
        "    \"\"\"Upload sample data to multiple leagues.\"\"\"\n",
        "    test_leagues = [\"E0\", \"D1\", \"SP1\", \"I1\", \"F1\"]\n",
        "\n",
        "    print(\"🚀 Starting bulk upload of sample data...\")\n",
        "    print(f\"Target leagues: {', '.join(test_leagues)}\")\n",
        "    print(\"⚠️  This will append 10 sample matches to each league\")\n",
        "\n",
        "    confirm = input(\"\\nContinue? (yes/no): \")\n",
        "    if confirm.lower() != 'yes':\n",
        "        print(\"❌ Operation cancelled.\")\n",
        "        return\n",
        "\n",
        "    success_count = 0\n",
        "    for league_code in test_leagues:\n",
        "        print(f\"\\n--- Processing {league_code} ({AVAILABLE_LEAGUES[league_code]}) ---\")\n",
        "        sample_data = generate_sample_data(league_code, 10)\n",
        "\n",
        "        if upload_data_to_league(league_code, sample_data):\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\"❌ Failed to upload to {league_code}, continuing...\")\n",
        "\n",
        "    print(f\"\\n🎉 Bulk upload completed!\")\n",
        "    print(f\"✅ Successfully uploaded to: {success_count}/{len(test_leagues)} leagues\")\n",
        "\n",
        "def interactive_data_upload():\n",
        "    \"\"\"Interactive menu for data upload operations.\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📤 HISTORICAL DATA UPLOAD TOOL\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"Available options:\")\n",
        "        print(\"1. Upload sample data to single league\")\n",
        "        print(\"2. Upload sample data to multiple leagues (bulk test)\")\n",
        "        print(\"3. Upload data from CSV file\")\n",
        "        print(\"4. Show available leagues\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-5): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            print(\"\\nAvailable leagues:\")\n",
        "            for code, name in AVAILABLE_LEAGUES.items():\n",
        "                print(f\"  {code}: {name}\")\n",
        "\n",
        "            league_code = input(\"\\nEnter league code: \").strip().upper()\n",
        "            if league_code in AVAILABLE_LEAGUES:\n",
        "                num_matches = int(input(\"Number of sample matches (default 10): \") or \"10\")\n",
        "                sample_data = generate_sample_data(league_code, num_matches)\n",
        "                print(sample_data)\n",
        "                time.sleep(3000)\n",
        "                upload_data_to_league(league_code, sample_data)\n",
        "            else:\n",
        "                print(\"❌ Invalid league code.\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            bulk_upload_sample_data()\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            file_path = input(\"Enter CSV file path: \").strip()\n",
        "            league_code = input(\"Enter target league code: \").strip().upper()\n",
        "\n",
        "            if league_code not in AVAILABLE_LEAGUES:\n",
        "                print(\"❌ Invalid league code.\")\n",
        "                continue\n",
        "\n",
        "            matches = read_csv_file(file_path)\n",
        "            if matches:\n",
        "                # This operation is now append-only. Existing data will not be cleared.\n",
        "                upload_data_to_league(league_code, matches)\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            print(\"\\nAll available leagues:\")\n",
        "            for code, name in AVAILABLE_LEAGUES.items():\n",
        "                print(f\"  {code:4s}: {name}\")\n",
        "\n",
        "        elif choice == \"5\":\n",
        "            print(\"👋 Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please enter 1-5.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # You can run this in different ways:\n",
        "\n",
        "    # Option 1: Interactive menu\n",
        "    #interactive_data_upload()\n",
        "\n",
        "    # Option 2: Upload sample data directly (will append)\n",
        "    # sample_data = generate_sample_data(\"E0\", 20)\n",
        "    # upload_data_to_league(\"E0\", sample_data)\n",
        "\n",
        "    # Option 3: Upload from CSV file (will append)\n",
        "    league_code = \"E1\"\n",
        "    matches = read_csv_file(\"new_data_to_upload/\"+league_code+\"_latestRun.csv\")\n",
        "    #matches = read_csv_file(\"combined_by_league/\"+league_code+\"__combined.csv\")\n",
        "\n",
        "    if len(matches)>0:\n",
        "        upload_data_to_league(league_code, matches)\n",
        "    else:\n",
        "      print(\"matches = empty ! No new records need to be uploaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtZRrwIDC-QF",
        "outputId": "445f6a01-1626-43ce-9561-2a0d03d9d452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Successfully read 695 matches from new_data_to_upload/E1_latestRun.csv\n",
            "🚀 Starting upload for Championship (E1)\n",
            "📊 Appending 695 matches...\n",
            "📞 Calling 'uploadHistoricalData' for league E1...\n",
            "✅ Success: Successfully appended 695 matches for E1\n",
            "   📋 Starting data APPEND process for E1 (History_E1)\n",
            "   📋 Received 695 matches to process\n",
            "   📋 Processed and validated 695 matches\n",
            "   📋 Appended batch 1/14 (50 records)\n",
            "   📋 Appended batch 2/14 (50 records)\n",
            "   📋 Appended batch 3/14 (50 records)\n",
            "   📋 Appended batch 4/14 (50 records)\n",
            "   📋 Appended batch 5/14 (50 records)\n",
            "   📋 Appended batch 6/14 (50 records)\n",
            "   📋 Appended batch 7/14 (50 records)\n",
            "   📋 Appended batch 8/14 (50 records)\n",
            "   📋 Appended batch 9/14 (50 records)\n",
            "   📋 Appended batch 10/14 (50 records)\n",
            "   📋 Appended batch 11/14 (50 records)\n",
            "   📋 Appended batch 12/14 (50 records)\n",
            "   📋 Appended batch 13/14 (50 records)\n",
            "   📋 Appended batch 14/14 (45 records)\n",
            "   📋 ✅ Successfully appended 695 matches for E1\n",
            "✅ Successfully appended 695 matches to E1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kg56KVK8NVJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXzSQ6uNDVIJ",
        "outputId": "a348f5b0-62c9-4a1c-96c8-0575c7cf943c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting full data processing pipeline...\n",
            "\n",
            "--- STEP 1: Calculating P&L for all leagues ---\n",
            "\n",
            "--- Processing League: E1 ---\n",
            "Processing batch 1 for E1 (offset: 0)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 0}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 2 for E1 (offset: 50)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 50}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 3 for E1 (offset: 100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 4 for E1 (offset: 150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 5 for E1 (offset: 200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 6 for E1 (offset: 250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 7 for E1 (offset: 300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 8 for E1 (offset: 350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 9 for E1 (offset: 400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 10 for E1 (offset: 450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 11 for E1 (offset: 500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 12 for E1 (offset: 550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 13 for E1 (offset: 600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 14 for E1 (offset: 650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 15 for E1 (offset: 700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 16 for E1 (offset: 750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 17 for E1 (offset: 800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 18 for E1 (offset: 850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 19 for E1 (offset: 900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 20 for E1 (offset: 950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 21 for E1 (offset: 1000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 22 for E1 (offset: 1050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 23 for E1 (offset: 1100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 24 for E1 (offset: 1150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 25 for E1 (offset: 1200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 26 for E1 (offset: 1250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 27 for E1 (offset: 1300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 28 for E1 (offset: 1350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 29 for E1 (offset: 1400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 30 for E1 (offset: 1450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 31 for E1 (offset: 1500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 32 for E1 (offset: 1550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 33 for E1 (offset: 1600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 34 for E1 (offset: 1650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 35 for E1 (offset: 1700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 36 for E1 (offset: 1750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 37 for E1 (offset: 1800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 38 for E1 (offset: 1850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 39 for E1 (offset: 1900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 40 for E1 (offset: 1950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 1950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 41 for E1 (offset: 2000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 42 for E1 (offset: 2050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 43 for E1 (offset: 2100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 44 for E1 (offset: 2150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 45 for E1 (offset: 2200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 46 for E1 (offset: 2250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 47 for E1 (offset: 2300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 48 for E1 (offset: 2350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 49 for E1 (offset: 2400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 50 for E1 (offset: 2450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 51 for E1 (offset: 2500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 52 for E1 (offset: 2550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 53 for E1 (offset: 2600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 54 for E1 (offset: 2650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 55 for E1 (offset: 2700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 56 for E1 (offset: 2750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 57 for E1 (offset: 2800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 58 for E1 (offset: 2850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 59 for E1 (offset: 2900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 60 for E1 (offset: 2950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 2950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 61 for E1 (offset: 3000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 62 for E1 (offset: 3050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 63 for E1 (offset: 3100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 64 for E1 (offset: 3150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 65 for E1 (offset: 3200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 66 for E1 (offset: 3250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 67 for E1 (offset: 3300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 68 for E1 (offset: 3350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 69 for E1 (offset: 3400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 70 for E1 (offset: 3450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 71 for E1 (offset: 3500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 72 for E1 (offset: 3550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 73 for E1 (offset: 3600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 74 for E1 (offset: 3650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 75 for E1 (offset: 3700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 76 for E1 (offset: 3750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 77 for E1 (offset: 3800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 78 for E1 (offset: 3850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 79 for E1 (offset: 3900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 80 for E1 (offset: 3950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 3950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 81 for E1 (offset: 4000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 82 for E1 (offset: 4050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 83 for E1 (offset: 4100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 84 for E1 (offset: 4150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 85 for E1 (offset: 4200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 86 for E1 (offset: 4250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 87 for E1 (offset: 4300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 88 for E1 (offset: 4350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 89 for E1 (offset: 4400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 90 for E1 (offset: 4450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 91 for E1 (offset: 4500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 92 for E1 (offset: 4550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 93 for E1 (offset: 4600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 94 for E1 (offset: 4650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 95 for E1 (offset: 4700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 96 for E1 (offset: 4750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 97 for E1 (offset: 4800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 98 for E1 (offset: 4850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 99 for E1 (offset: 4900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 100 for E1 (offset: 4950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 4950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 101 for E1 (offset: 5000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 102 for E1 (offset: 5050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 103 for E1 (offset: 5100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 104 for E1 (offset: 5150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 105 for E1 (offset: 5200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 106 for E1 (offset: 5250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 107 for E1 (offset: 5300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 108 for E1 (offset: 5350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 109 for E1 (offset: 5400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 110 for E1 (offset: 5450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 111 for E1 (offset: 5500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 112 for E1 (offset: 5550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 113 for E1 (offset: 5600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 114 for E1 (offset: 5650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 115 for E1 (offset: 5700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 116 for E1 (offset: 5750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 117 for E1 (offset: 5800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 118 for E1 (offset: 5850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 119 for E1 (offset: 5900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 120 for E1 (offset: 5950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 5950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 121 for E1 (offset: 6000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 122 for E1 (offset: 6050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 123 for E1 (offset: 6100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 124 for E1 (offset: 6150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 125 for E1 (offset: 6200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 126 for E1 (offset: 6250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 127 for E1 (offset: 6300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 128 for E1 (offset: 6350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 129 for E1 (offset: 6400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 130 for E1 (offset: 6450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 131 for E1 (offset: 6500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 132 for E1 (offset: 6550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 133 for E1 (offset: 6600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 134 for E1 (offset: 6650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 135 for E1 (offset: 6700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 136 for E1 (offset: 6750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 137 for E1 (offset: 6800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 138 for E1 (offset: 6850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 139 for E1 (offset: 6900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 140 for E1 (offset: 6950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 6950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 141 for E1 (offset: 7000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 142 for E1 (offset: 7050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 143 for E1 (offset: 7100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 144 for E1 (offset: 7150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 145 for E1 (offset: 7200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 146 for E1 (offset: 7250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 147 for E1 (offset: 7300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 148 for E1 (offset: 7350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 149 for E1 (offset: 7400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 150 for E1 (offset: 7450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 151 for E1 (offset: 7500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 152 for E1 (offset: 7550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 153 for E1 (offset: 7600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 154 for E1 (offset: 7650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 155 for E1 (offset: 7700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 156 for E1 (offset: 7750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 157 for E1 (offset: 7800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 158 for E1 (offset: 7850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 159 for E1 (offset: 7900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 160 for E1 (offset: 7950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 7950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 161 for E1 (offset: 8000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 162 for E1 (offset: 8050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 163 for E1 (offset: 8100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 164 for E1 (offset: 8150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 165 for E1 (offset: 8200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 166 for E1 (offset: 8250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 167 for E1 (offset: 8300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 168 for E1 (offset: 8350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 169 for E1 (offset: 8400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 170 for E1 (offset: 8450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 171 for E1 (offset: 8500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 172 for E1 (offset: 8550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 173 for E1 (offset: 8600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 174 for E1 (offset: 8650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 175 for E1 (offset: 8700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 176 for E1 (offset: 8750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 177 for E1 (offset: 8800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 178 for E1 (offset: 8850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 179 for E1 (offset: 8900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 180 for E1 (offset: 8950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 8950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 181 for E1 (offset: 9000)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9000}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 182 for E1 (offset: 9050)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9050}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 183 for E1 (offset: 9100)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9100}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 184 for E1 (offset: 9150)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9150}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 185 for E1 (offset: 9200)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9200}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 186 for E1 (offset: 9250)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9250}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 187 for E1 (offset: 9300)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9300}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 188 for E1 (offset: 9350)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9350}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 189 for E1 (offset: 9400)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9400}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 190 for E1 (offset: 9450)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9450}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 191 for E1 (offset: 9500)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9500}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 192 for E1 (offset: 9550)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9550}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 193 for E1 (offset: 9600)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9600}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 194 for E1 (offset: 9650)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9650}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 195 for E1 (offset: 9700)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9700}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 196 for E1 (offset: 9750)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9750}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 197 for E1 (offset: 9800)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9800}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 198 for E1 (offset: 9850)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9850}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 199 for E1 (offset: 9900)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9900}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n",
            "Processing batch 200 for E1 (offset: 9950)...\n",
            "📞 Calling 'calculateE1Pnl' with payload: {\"offset\": 9950}\n",
            "✅ calculateE1Pnl success: Processed 50 matches.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "⚠️ Warning: Reached max batches for E1. May be incomplete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing League: E0 ---\n",
            "Processing batch 1 for E0 (offset: 0)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 0}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 2 for E0 (offset: 50)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 50}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 3 for E0 (offset: 100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 4 for E0 (offset: 150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 5 for E0 (offset: 200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 6 for E0 (offset: 250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 7 for E0 (offset: 300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 8 for E0 (offset: 350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 9 for E0 (offset: 400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 10 for E0 (offset: 450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 11 for E0 (offset: 500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 12 for E0 (offset: 550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 13 for E0 (offset: 600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 14 for E0 (offset: 650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 15 for E0 (offset: 700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 16 for E0 (offset: 750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 17 for E0 (offset: 800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 18 for E0 (offset: 850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 19 for E0 (offset: 900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 20 for E0 (offset: 950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 21 for E0 (offset: 1000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 22 for E0 (offset: 1050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 23 for E0 (offset: 1100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 24 for E0 (offset: 1150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 25 for E0 (offset: 1200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 26 for E0 (offset: 1250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 27 for E0 (offset: 1300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 28 for E0 (offset: 1350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 29 for E0 (offset: 1400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 30 for E0 (offset: 1450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 31 for E0 (offset: 1500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 32 for E0 (offset: 1550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 33 for E0 (offset: 1600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 34 for E0 (offset: 1650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 35 for E0 (offset: 1700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 36 for E0 (offset: 1750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 37 for E0 (offset: 1800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 38 for E0 (offset: 1850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 39 for E0 (offset: 1900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 40 for E0 (offset: 1950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 1950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 41 for E0 (offset: 2000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 42 for E0 (offset: 2050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 43 for E0 (offset: 2100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 44 for E0 (offset: 2150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 45 for E0 (offset: 2200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 46 for E0 (offset: 2250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 47 for E0 (offset: 2300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 48 for E0 (offset: 2350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 49 for E0 (offset: 2400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 50 for E0 (offset: 2450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 51 for E0 (offset: 2500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 52 for E0 (offset: 2550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 53 for E0 (offset: 2600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 54 for E0 (offset: 2650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 55 for E0 (offset: 2700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 56 for E0 (offset: 2750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 57 for E0 (offset: 2800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 58 for E0 (offset: 2850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 59 for E0 (offset: 2900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 60 for E0 (offset: 2950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 2950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 61 for E0 (offset: 3000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 62 for E0 (offset: 3050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 63 for E0 (offset: 3100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 64 for E0 (offset: 3150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 65 for E0 (offset: 3200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 66 for E0 (offset: 3250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 67 for E0 (offset: 3300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 68 for E0 (offset: 3350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 69 for E0 (offset: 3400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 70 for E0 (offset: 3450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 71 for E0 (offset: 3500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 72 for E0 (offset: 3550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 73 for E0 (offset: 3600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 74 for E0 (offset: 3650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 75 for E0 (offset: 3700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 76 for E0 (offset: 3750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 77 for E0 (offset: 3800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 78 for E0 (offset: 3850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 79 for E0 (offset: 3900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 80 for E0 (offset: 3950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 3950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 81 for E0 (offset: 4000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 82 for E0 (offset: 4050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 83 for E0 (offset: 4100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 84 for E0 (offset: 4150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 85 for E0 (offset: 4200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 86 for E0 (offset: 4250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 87 for E0 (offset: 4300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 88 for E0 (offset: 4350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 89 for E0 (offset: 4400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 90 for E0 (offset: 4450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 91 for E0 (offset: 4500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 92 for E0 (offset: 4550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 93 for E0 (offset: 4600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 94 for E0 (offset: 4650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 95 for E0 (offset: 4700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 96 for E0 (offset: 4750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 97 for E0 (offset: 4800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 98 for E0 (offset: 4850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 99 for E0 (offset: 4900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 100 for E0 (offset: 4950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 4950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 101 for E0 (offset: 5000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 102 for E0 (offset: 5050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 103 for E0 (offset: 5100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 104 for E0 (offset: 5150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 105 for E0 (offset: 5200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 106 for E0 (offset: 5250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 107 for E0 (offset: 5300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 108 for E0 (offset: 5350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 109 for E0 (offset: 5400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 110 for E0 (offset: 5450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 111 for E0 (offset: 5500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 112 for E0 (offset: 5550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 113 for E0 (offset: 5600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 114 for E0 (offset: 5650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 115 for E0 (offset: 5700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 116 for E0 (offset: 5750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 117 for E0 (offset: 5800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 118 for E0 (offset: 5850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 119 for E0 (offset: 5900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 120 for E0 (offset: 5950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 5950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 121 for E0 (offset: 6000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 122 for E0 (offset: 6050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 123 for E0 (offset: 6100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 124 for E0 (offset: 6150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 125 for E0 (offset: 6200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 126 for E0 (offset: 6250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 127 for E0 (offset: 6300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 128 for E0 (offset: 6350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 129 for E0 (offset: 6400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 130 for E0 (offset: 6450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 131 for E0 (offset: 6500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 132 for E0 (offset: 6550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 133 for E0 (offset: 6600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 134 for E0 (offset: 6650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 135 for E0 (offset: 6700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 136 for E0 (offset: 6750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6750}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 137 for E0 (offset: 6800)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6800}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 138 for E0 (offset: 6850)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6850}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 139 for E0 (offset: 6900)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6900}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 140 for E0 (offset: 6950)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 6950}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 141 for E0 (offset: 7000)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7000}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 142 for E0 (offset: 7050)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7050}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 143 for E0 (offset: 7100)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7100}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 144 for E0 (offset: 7150)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7150}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 145 for E0 (offset: 7200)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7200}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 146 for E0 (offset: 7250)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7250}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 147 for E0 (offset: 7300)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7300}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 148 for E0 (offset: 7350)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7350}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 149 for E0 (offset: 7400)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7400}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 150 for E0 (offset: 7450)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7450}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 151 for E0 (offset: 7500)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7500}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 152 for E0 (offset: 7550)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7550}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 153 for E0 (offset: 7600)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7600}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 154 for E0 (offset: 7650)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7650}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 155 for E0 (offset: 7700)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7700}\n",
            "✅ calculateE0Pnl success: Processed 50 matches.\n",
            "Processing batch 156 for E0 (offset: 7750)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7750}\n",
            "✅ calculateE0Pnl success: Processed 25 matches.\n",
            "Processing batch 157 for E0 (offset: 7775)...\n",
            "📞 Calling 'calculateE0Pnl' with payload: {\"offset\": 7775}\n",
            "✅ calculateE0Pnl success: Completed\n",
            "🏁 Finished processing E0.\n",
            "\n",
            "🎉 Pipeline completed in 724.8 seconds!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# --- ⚙️ CONFIGURATION ---\n",
        "APP_HOSTNAME = \"betmechs-ee8f45ee.base44.app\"\n",
        "BASE44_API_KEY = \"09b8177c650048309207ea18b26b58fb\"\n",
        "BATCH_SIZE = 50\n",
        "MAX_BATCHES = 200 # Safety limit to prevent infinite loops\n",
        "\n",
        "# --- Pipeline Functions ---\n",
        "LEAGUE_PNL_FUNCTIONS = {\n",
        "    \"E1\": \"calculateE1Pnl\",\"E0\": \"calculateE0Pnl\",\n",
        "}\n",
        "INDEX_CREATION_FUNCTIONS = [\n",
        "    \"createPremierLeagueIndexes\", \"createBundesligaIndexes\", \"createLaLigaIndexes\",\n",
        "    \"createSerieAIndexes\", \"createLigue1Indexes\",\n",
        "]\n",
        "PERFORMANCE_CALCULATION_FUNCTIONS = [\n",
        "    \"calculatePremierLeaguePerformance\", \"calculateBundesligaPerformance\", \"calculateLaLigaPerformance\",\n",
        "    \"calculateSerieAPerformance\", \"createLigue1Performance\",\n",
        "]\n",
        "\n",
        "def call_backend_function(function_name, payload={}, timeout=60):\n",
        "    \"\"\"Helper to call backend functions.\"\"\"\n",
        "    url = f\"https://{APP_HOSTNAME}/api/functions/{function_name}\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {BASE44_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    print(f\"📞 Calling '{function_name}' with payload: {json.dumps(payload)}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        response_data = response.json()\n",
        "        print(f\"✅ {function_name} success: {response_data.get('message', 'OK')}\")\n",
        "        return True, response_data\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ ERROR in '{function_name}': {e}\", file=sys.stderr)\n",
        "        if hasattr(e, 'response') and e.response:\n",
        "            try:\n",
        "                error_details = e.response.json()\n",
        "                print(f\"   Response: {error_details}\", file=sys.stderr)\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"   Response (non-JSON): {e.response.text}\", file=sys.stderr)\n",
        "        return False, None\n",
        "\n",
        "def run_full_pipeline():\n",
        "    \"\"\"Run the full data processing pipeline from P&L to performance.\"\"\"\n",
        "    start_time = time.time()\n",
        "    print(\"🚀 Starting full data processing pipeline...\\n\")\n",
        "\n",
        "    # --- STEP 1: Calculate P&L for each league using batch processing ---\n",
        "    print(\"--- STEP 1: Calculating P&L for all leagues ---\")\n",
        "    for league_code, pnl_func in LEAGUE_PNL_FUNCTIONS.items():\n",
        "        print(f\"\\n--- Processing League: {league_code} ---\")\n",
        "\n",
        "        # 1a. Clear existing P&L data\n",
        "        #print(f\"Clearing old P&L data for {league_code}...\")\n",
        "        #success, _ = call_backend_function(\"clearPnlHistory\", {\"leagueCode\": league_code})\n",
        "        #if not success:\n",
        "        #    print(f\"🚨 Failed to clear P&L for {league_code}. Aborting this league.\", file=sys.stderr)\n",
        "        #    continue\n",
        "\n",
        "        # 1b. Process P&L in batches\n",
        "        offset = 0\n",
        "        for i in range(MAX_BATCHES):\n",
        "            print(f\"Processing batch {i+1} for {league_code} (offset: {offset})...\")\n",
        "            success, data = call_backend_function(pnl_func, {\"offset\": offset})\n",
        "\n",
        "            if not success:\n",
        "                print(f\"🚨 Batch failed for {league_code}. Aborting this league.\", file=sys.stderr)\n",
        "                break\n",
        "\n",
        "            processed_count = data.get(\"processedCount\", 0)\n",
        "            if processed_count == 0:\n",
        "                print(f\"🏁 Finished processing {league_code}.\")\n",
        "                break\n",
        "\n",
        "            offset += processed_count\n",
        "            time.sleep(0.5) # Small delay to avoid overwhelming the server\n",
        "        else:\n",
        "            print(f\"⚠️ Warning: Reached max batches for {league_code}. May be incomplete.\", file=sys.stderr)\n",
        "\n",
        "    \"\"\"\n",
        "    # --- STEP 2: Create betting indexes ---\n",
        "    print(\"\\n--- STEP 2: Creating betting indexes ---\")\n",
        "    for func_name in INDEX_CREATION_FUNCTIONS:\n",
        "        success, _ = call_backend_function(func_name, {})\n",
        "        if not success:\n",
        "            print(f\"🚨 Failed on {func_name}. Continuing...\", file=sys.stderr)\n",
        "        time.sleep(1)\n",
        "\n",
        "    # --- STEP 3: Calculate strategy performance ---\n",
        "    print(\"\\n--- STEP 3: Calculating strategy performance ---\")\n",
        "    for func_name in PERFORMANCE_CALCULATION_FUNCTIONS:\n",
        "        success, _ = call_backend_function(func_name, {})\n",
        "        if not success:\n",
        "            print(f\"🚨 Failed on {func_name}. Continuing...\", file=sys.stderr)\n",
        "        time.sleep(1)\n",
        "     \"\"\"\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"\\n🎉 Pipeline completed in {end_time - start_time:.1f} seconds!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_full_pipeline()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrIXsjdzOMU823MVRNDqWL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}